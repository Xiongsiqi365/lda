gensim.models.ldamulticore.LdaMulticore(corpus=None, num_topics=100, id2word=None,
    workers=None, chunksize=2000, passes=1, batch=False, alpha='symmetric',
    eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50,
    gamma_threshold=0.001, random_state=None, minimum_probability=0.01,
    minimum_phi_value=0.01, per_word_topics=False, dtype=<class 'numpy.float32'>)
    
<big>Parameters</big>
corpus ({iterable of list of (int, float), scipy.sparse.csc}, optional) – Stream of document vectors or sparse matrix of shape (num_documents, num_terms). If not given, the model is left untrained (presumably because you want to call update() manually).

num_topics (int, optional) – The number of requested latent topics to be extracted from the training corpus.

id2word ({dict of (int, str), gensim.corpora.dictionary.Dictionary}) – Mapping from word IDs to words. It is used to determine the vocabulary size, as well as for debugging and topic printing.

workers (int, optional) – Number of workers processes to be used for parallelization. If None all available cores (as estimated by workers=cpu_count()-1 will be used. Note however that for hyper-threaded CPUs, this estimation returns a too high number – set workers directly to the number of your real cores (not hyperthreads) minus one, for optimal performance.

chunksize (int, optional) – Number of documents to be used in each training chunk.

passes (int, optional) – Number of passes through the corpus during training.

alpha ({float, numpy.ndarray of float, list of float, str}, optional) –

A-priori belief on document-topic distribution, this can be:
scalar for a symmetric prior over document-topic distribution,

1D array of length equal to num_topics to denote an asymmetric user defined prior for each topic.

Alternatively default prior selecting strategies can be employed by supplying a string:
’symmetric’: (default) Uses a fixed symmetric prior of 1.0 / num_topics,

’asymmetric’: Uses a fixed normalized asymmetric prior of 1.0 / (topic_index + sqrt(num_topics)).

eta ({float, numpy.ndarray of float, list of float, str}, optional) –

A-priori belief on topic-word distribution, this can be:
scalar for a symmetric prior over topic-word distribution,

1D array of length equal to num_words to denote an asymmetric user defined prior for each word,

matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination.

Alternatively default prior selecting strategies can be employed by supplying a string:
’symmetric’: (default) Uses a fixed symmetric prior of 1.0 / num_topics,

’auto’: Learns an asymmetric prior from the corpus.

decay (float, optional) – A number between (0.5, 1] to weight what percentage of the previous lambda value is forgotten when each new document is examined. Corresponds to \kappa from ‘Online Learning for LDA’ by Hoffman et al.

offset (float, optional) – Hyper-parameter that controls how much we will slow down the first steps the first few iterations. Corresponds to \tau_0 from ‘Online Learning for LDA’ by Hoffman et al.

eval_every (int, optional) – Log perplexity is estimated every that many updates. Setting this to one slows down training by ~2x.

iterations (int, optional) – Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.

gamma_threshold (float, optional) – Minimum change in the value of the gamma parameters to continue iterating.

minimum_probability (float, optional) – Topics with a probability lower than this threshold will be filtered out.

random_state ({np.random.RandomState, int}, optional) – Either a randomState object or a seed to generate one. Useful for reproducibility. Note that results can still vary due to non-determinism in OS scheduling of the worker processes.

minimum_phi_value (float, optional) – if per_word_topics is True, this represents a lower bound on the term probabilities.

per_word_topics (bool) – If True, the model also computes a list of topics, sorted in descending order of most likely topics for each word, along with their phi values multiplied by the feature length (i.e. word count).

dtype ({numpy.float16, numpy.float32, numpy.float64}, optional) – Data-type to use during calculations inside model. All inputs are also converted.
